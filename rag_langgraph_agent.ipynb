{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3c9a0c-8fe6-43af-b62c-a3289681f9eb",
   "metadata": {},
   "source": [
    "# RAG Agent (LangGraph + LangChain + Chroma)\n",
    "\n",
    "This notebook ingests documents from `data/`, builds a Chroma vector DB with local embeddings, and wires a simple LangGraph RAG agent you can run locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce93ca6-75c5-4059-8d5a-515a698838e6",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "Create and activate a virtual environment, then install requirements:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "044c6dc8-11f5-4b71-b591-b75dd1f199da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & logging\n",
    "import os, logging\n",
    "from rich.logging import RichHandler\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(message)s\", handlers=[RichHandler(rich_tracebacks=True)])\n",
    "log = logging.getLogger(\"nb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c17bfda0-638a-4545-84ff-e2a095a8b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "DATA_DIR = r\"C:\\Users\\sangi\\Downloads\\Medical\"\n",
    "DB_DIR = \"chroma_db\"\n",
    "EMBED_MODEL_NAME = \"all-MiniLM-L6-v2\"  # SentenceTransformers model (no API key needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92fc0004-a8b9-4981-9ea9-f6cf1fef1c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain / LangGraph / Chroma imports\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, DirectoryLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58531b06-9e0b-4436-abb7-c321808c766f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Load documents\n",
    "from pathlib import Path\n",
    "\n",
    "def load_documents(data_dir: str) -> List[Document]:\n",
    "    docs: List[Document] = []\n",
    "    p = Path(data_dir)\n",
    "    assert p.exists(), f\"{data_dir} not found — create it and add PDFs or text files.\"\n",
    "    for fname in os.listdir(data_dir):\n",
    "        fp = p / fname\n",
    "        if fname.lower().endswith(\".pdf\"):\n",
    "            docs.extend(PyPDFLoader(str(fp)).load())\n",
    "        elif fname.lower().endswith((\".txt\", \".md\")):\n",
    "            docs.extend(TextLoader(str(fp), encoding=\"utf-8\").load())\n",
    "    return docs\n",
    "\n",
    "docs = load_documents(DATA_DIR)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3be71f1-8eed-4cdc-a8fa-08894986f1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-6.2.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Downloading pypdf-6.2.0-py3-none-any.whl (326 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-6.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ydantic (C:\\Users\\sangi\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ydantic (C:\\Users\\sangi\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ydantic (C:\\Users\\sangi\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2694ee34-5c7b-439b-8a21-8b8571603149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangi\\AppData\\Local\\Temp\\ipykernel_23176\\1442801060.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedder = SentenceTransformerEmbeddings(model_name=EMBED_MODEL_NAME)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/12/25 13:44:50] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Use pytorch device_name: cpu                                <a href=\"file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">SentenceTransformer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py#219\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">219</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/12/25 13:44:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Use pytorch device_name: cpu                                \u001b]8;id=9604;file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\u001b\\\u001b[2mSentenceTransformer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=494192;file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py#219\u001b\\\u001b[2m219\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Load pretrained SentenceTransformer: all-MiniLM-L6-v2       <a href=\"file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">SentenceTransformer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py#227\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">227</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Load pretrained SentenceTransformer: all-MiniLM-L6-v2       \u001b]8;id=846817;file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\u001b\\\u001b[2mSentenceTransformer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=767862;file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py#227\u001b\\\u001b[2m227\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/12/25 13:44:55] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Anonymized telemetry enabled. See                                        <a href=\"file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\chromadb\\telemetry\\product\\posthog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">posthog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\chromadb\\telemetry\\product\\posthog.py#22\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://docs.trychroma.com/telemetry</span> for more information.               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/12/25 13:44:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Anonymized telemetry enabled. See                                        \u001b]8;id=284460;file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\chromadb\\telemetry\\product\\posthog.py\u001b\\\u001b[2mposthog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=271605;file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\chromadb\\telemetry\\product\\posthog.py#22\u001b\\\u001b[2m22\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://docs.trychroma.com/telemetry\u001b[0m for more information.               \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangi\\AppData\\Local\\Temp\\ipykernel_23176\\1442801060.py:8: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vs.persist()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3641"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Split & embed, then build (or refresh) Chroma vectorstore\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=900, chunk_overlap=120, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"])\n",
    "splits = splitter.split_documents(docs)\n",
    "embedder = SentenceTransformerEmbeddings(model_name=EMBED_MODEL_NAME)\n",
    "\n",
    "# Fresh build\n",
    "vs = Chroma.from_documents(splits, embedder, persist_directory=DB_DIR)\n",
    "vs.persist()\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0388ef72-b766-433a-9512-e818b564a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Define graph state and nodes\n",
    "class AgentState(BaseModel):\n",
    "    messages: List[Dict[str, Any]] = Field(default_factory=list)\n",
    "    context: List[str] = Field(default_factory=list)\n",
    "\n",
    "def retrieve_node(state: AgentState) -> AgentState:\n",
    "    question = \"\"\n",
    "    for m in reversed(state.messages):\n",
    "        if m.get(\"role\") == \"user\":\n",
    "            question = m.get(\"content\", \"\")\n",
    "            break\n",
    "    if not question:\n",
    "        return state\n",
    "\n",
    "    client = SentenceTransformerEmbeddings(model_name=EMBED_MODEL_NAME)\n",
    "    vs = Chroma(persist_directory=DB_DIR, embedding_function=client)\n",
    "    retrieved = vs.similarity_search(question, k=5)\n",
    "    ctx = [f\"[{i+1}] {d.page_content}\" for i, d in enumerate(retrieved)]\n",
    "    state.context = ctx\n",
    "    return state\n",
    "\n",
    "def answer_node(state: AgentState) -> AgentState:\n",
    "    question = \"\"\n",
    "    for m in reversed(state.messages):\n",
    "        if m.get(\"role\") == \"user\":\n",
    "            question = m.get(\"content\", \"\")\n",
    "            break\n",
    "\n",
    "    if not state.context:\n",
    "        answer = \"I couldn't find relevant context. Try rephrasing or adding more documents.\"\n",
    "    else:\n",
    "        summary = \"\\n\\n\".join(state.context)\n",
    "        answer = f\"Q: {question}\\n\\nTop context:\\n{summary}\\n\\nDraft answer (summarize and cite the numbered chunks above).\"\n",
    "\n",
    "    state.messages.append({ \"role\": \"assistant\", \"content\": answer })\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f01a1184-546f-414e-bba5-82ffd4c2ab51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000026A2EA6E6F0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Wire the graph\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"retrieve\", retrieve_node)\n",
    "graph.add_node(\"answer\", answer_node)\n",
    "graph.set_entry_point(\"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"answer\")\n",
    "graph.add_edge(\"answer\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60c79085-ad6e-47cf-ae8e-0e980471d3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/12/25 14:00:49] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Use pytorch device_name: cpu                                <a href=\"file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">SentenceTransformer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py#219\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">219</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/12/25 14:00:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Use pytorch device_name: cpu                                \u001b]8;id=14165;file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\u001b\\\u001b[2mSentenceTransformer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=56013;file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py#219\u001b\\\u001b[2m219\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Load pretrained SentenceTransformer: all-MiniLM-L6-v2       <a href=\"file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">SentenceTransformer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py#227\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">227</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Load pretrained SentenceTransformer: all-MiniLM-L6-v2       \u001b]8;id=29297;file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\u001b\\\u001b[2mSentenceTransformer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=204120;file://C:\\Users\\sangi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py#227\u001b\\\u001b[2m227\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': 'What are the main requirements of the interview task?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"Q: What are the main requirements of the interview task?\\n\\nTop context:\\n[1] # Interview Task — Extracted Requirements\\n\\nBelow is an automatic extraction of the task requirements from the provided PDF. Review and edit as needed.\\n\\n## Heuristic Requirements Summary\\nTask Requirements (heuristic extraction)\\n\\n- \\n\\n---\\n\\n## Full Extracted Text (for reference)\\n> This section includes the raw text extracted from the PDF so you can refine the final requirements manually if needed.\\n\\n```\\ntext_extraction_log=['Extracted text with PyPDF2.']\\n\\n\\n===== PAGE 1 =====\\n \\n \\n \\n\\n \\n\\n \\n\\n\\n \\n\\n \\n\\n\\n\\n\\n \\n \\n\\n \\n \\n \\n\\n \\n \\n \\n \\n\\n \\n\\n\\n \\n1.\\n \\n \\n\\n\\n\\n\\n \\n2.\\n \\n\\n\\n \\n \\n\\n\\n\\n \\n3.\\n \\n\\n\\n\\n\\n \\n \\n4.\\n \\n\\n\\n\\n\\n \\n \\n\\n\\n \\n\\n \\n \\n\\n\\n \\n\\n \\n\\n\\n\\n \\n\\n \\n\\n\\n\\n \\n \\n\\n \\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n \\n\\n \\n\\n\\n\\n \\n\\n \\n\\n \\n\\n\\n\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n===== PAGE 2 =====\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n \\n\\n \\n \\n\\n \\n\\n \\n \\n\\n \\n\\n \\n\\n \\n\\n\\n \\n\\n\\n \\n\\n \\n\\n \\n\\n\\n \\n\\n\\n \\n\\n \\n \\n\\n\\n\\n\\n \\n\\n \\n\\n \\n \\n \\n \\n \\n\\n \\n\\n \\n\\n\\n\\n\\n\\n \\n\\n \\n\\n\\n\\n\\n\\n\\n \\n\\n```\\n\\n[2] # RAG Agent (LangGraph + LangChain + Chroma)\\n\\nThis repo is a ready-to-run scaffold tailored to your interview task PDF. It includes:\\n- A Jupyter notebook to ingest your docs, build a Chroma vector DB with **SentenceTransformers** embeddings, and run a **LangGraph**-powered RAG agent.\\n- A Python script (`app.py`) that builds the same graph for quick CLI/manual testing.\\n- `TASK.md` with the auto-extracted requirements for review.\\n\\n## Quickstart\\n\\n1. Create a virtual env and install requirements:\\n   ```bash\\n   pip install -r requirements.txt\\n   ```\\n\\n2. Put your source documents into `data/` (your uploaded PDF is already copied as `data/source.pdf`).\\n\\n3. Open the notebook:\\n   ```bash\\n   jupyter lab  # or jupyter notebook\\n   ```\\n\\n4. Run the notebook cells to:\\n   - Load & split documents\\n   - Build embeddings & Chroma store\\n   - Construct the LangGraph\\n   - Query the agent\\n\\n[3] \\uf0b7 Use Hugging Face or OpenAI embeddings for vector creation. \\n\\uf0b7 Include minimal logging or print statements to show each step’s output (plan \\n→ retrieve → answer → reflect). \\n\\uf0b7 The code should run locally in a Jupyter notebook or Python script. \\n\\uf0b7 Include requirements.txt file \\n \\nBonus Points: \\n\\uf0b7 Add a simple Streamlit or Gradio UI to ask questions interactively. \\n\\uf0b7 Use LangSmith or TruLens for trace and evaluation logging. \\n\\uf0b7 Add a short report (1–2 paragraphs) describing how your agent works and \\nwhat challenges you faced. \\n\\uf0b7 Include an evaluation code to evaluate the agent output (RAGAs or any LLM \\nas a Judge method or BLEU/ROUGE/BERTScore etc.) \\n \\nSubmission: \\n\\uf0b7 Submit a Jupyter Notebook (.ipynb) or Python script (.py) file. \\n\\uf0b7 Include a README.md describing setup steps and your approach.\\n\\n[4] TASK 1 \\n \\nObjective: \\nCreate a basic AI agent using LangGraph or similar AI Agent framework that can \\nanswer questions from a small knowledge base using RAG (Retrieval-Augmented \\nGeneration). \\nThe goal is to test your understanding of AI agent workflows, RAG pipeline design, \\nand LangGraph basics. \\n \\nProject Description: \\nYou are required to build a Q&A AI Agent that can: \\n1. Accept a user question (e.g., “What are the benefits of renewable energy?”) \\n2. Retrieve relevant information from a small text dataset (you can use a few .txt \\nfiles or PDFs related with the questions you are expecting). \\n3. Use an LLM (e.g., OpenAI, Gemini,  Claude or Groq/HuggingFace) to \\ngenerate an answer using the retrieved context. \\n4. Show a simple reflection or validation step where the agent checks if the \\nanswer is relevant to the question. \\nThe agent workflow should have at least four LangGraph nodes:\\n\\n[5] or pulse rate affected by anxiety, or may look pale or per-\\nspire heavily, but others may appear physically completely\\nnormal. The doctor will then take the patient’s medication,\\ndietary, and occupational history to see if they are taking\\nprescription drugs that might cause anxiety, if they are\\nabusing alcohol or mood-altering drugs, if they are con-\\nsuming large amounts of caffeine, or if their workplace is\\nnoisy or dangerous. In most cases, the most important\\nsource of diagnostic information is the patient’s psycholog-\\nical and social history. The doctor may administer a brief\\npsychological test to help evaluate the intensity of the\\npatient’s anxiety and some of its features. Some tests that\\nare often given include the Hamilton Anxiety Scale and the\\nAnxiety Disorders Interview Schedule (ADIS). Many doc-\\ntors will check a number of chemical factors in the blood,\\n\\nDraft answer (summarize and cite the numbered chunks above).\"}],\n",
       " 'context': [\"[1] # Interview Task — Extracted Requirements\\n\\nBelow is an automatic extraction of the task requirements from the provided PDF. Review and edit as needed.\\n\\n## Heuristic Requirements Summary\\nTask Requirements (heuristic extraction)\\n\\n- \\n\\n---\\n\\n## Full Extracted Text (for reference)\\n> This section includes the raw text extracted from the PDF so you can refine the final requirements manually if needed.\\n\\n```\\ntext_extraction_log=['Extracted text with PyPDF2.']\\n\\n\\n===== PAGE 1 =====\\n \\n \\n \\n\\n \\n\\n \\n\\n\\n \\n\\n \\n\\n\\n\\n\\n \\n \\n\\n \\n \\n \\n\\n \\n \\n \\n \\n\\n \\n\\n\\n \\n1.\\n \\n \\n\\n\\n\\n\\n \\n2.\\n \\n\\n\\n \\n \\n\\n\\n\\n \\n3.\\n \\n\\n\\n\\n\\n \\n \\n4.\\n \\n\\n\\n\\n\\n \\n \\n\\n\\n \\n\\n \\n \\n\\n\\n \\n\\n \\n\\n\\n\\n \\n\\n \\n\\n\\n\\n \\n \\n\\n \\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n \\n\\n \\n\\n\\n\\n \\n\\n \\n\\n \\n\\n\\n\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n===== PAGE 2 =====\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n \\n\\n \\n \\n\\n \\n\\n \\n \\n\\n \\n\\n \\n\\n \\n\\n\\n \\n\\n\\n \\n\\n \\n\\n \\n\\n\\n \\n\\n\\n \\n\\n \\n \\n\\n\\n\\n\\n \\n\\n \\n\\n \\n \\n \\n \\n \\n\\n \\n\\n \\n\\n\\n\\n\\n\\n \\n\\n \\n\\n\\n\\n\\n\\n\\n \\n\\n```\",\n",
       "  '[2] # RAG Agent (LangGraph + LangChain + Chroma)\\n\\nThis repo is a ready-to-run scaffold tailored to your interview task PDF. It includes:\\n- A Jupyter notebook to ingest your docs, build a Chroma vector DB with **SentenceTransformers** embeddings, and run a **LangGraph**-powered RAG agent.\\n- A Python script (`app.py`) that builds the same graph for quick CLI/manual testing.\\n- `TASK.md` with the auto-extracted requirements for review.\\n\\n## Quickstart\\n\\n1. Create a virtual env and install requirements:\\n   ```bash\\n   pip install -r requirements.txt\\n   ```\\n\\n2. Put your source documents into `data/` (your uploaded PDF is already copied as `data/source.pdf`).\\n\\n3. Open the notebook:\\n   ```bash\\n   jupyter lab  # or jupyter notebook\\n   ```\\n\\n4. Run the notebook cells to:\\n   - Load & split documents\\n   - Build embeddings & Chroma store\\n   - Construct the LangGraph\\n   - Query the agent',\n",
       "  '[3] \\uf0b7 Use Hugging Face or OpenAI embeddings for vector creation. \\n\\uf0b7 Include minimal logging or print statements to show each step’s output (plan \\n→ retrieve → answer → reflect). \\n\\uf0b7 The code should run locally in a Jupyter notebook or Python script. \\n\\uf0b7 Include requirements.txt file \\n \\nBonus Points: \\n\\uf0b7 Add a simple Streamlit or Gradio UI to ask questions interactively. \\n\\uf0b7 Use LangSmith or TruLens for trace and evaluation logging. \\n\\uf0b7 Add a short report (1–2 paragraphs) describing how your agent works and \\nwhat challenges you faced. \\n\\uf0b7 Include an evaluation code to evaluate the agent output (RAGAs or any LLM \\nas a Judge method or BLEU/ROUGE/BERTScore etc.) \\n \\nSubmission: \\n\\uf0b7 Submit a Jupyter Notebook (.ipynb) or Python script (.py) file. \\n\\uf0b7 Include a README.md describing setup steps and your approach.',\n",
       "  '[4] TASK 1 \\n \\nObjective: \\nCreate a basic AI agent using LangGraph or similar AI Agent framework that can \\nanswer questions from a small knowledge base using RAG (Retrieval-Augmented \\nGeneration). \\nThe goal is to test your understanding of AI agent workflows, RAG pipeline design, \\nand LangGraph basics. \\n \\nProject Description: \\nYou are required to build a Q&A AI Agent that can: \\n1. Accept a user question (e.g., “What are the benefits of renewable energy?”) \\n2. Retrieve relevant information from a small text dataset (you can use a few .txt \\nfiles or PDFs related with the questions you are expecting). \\n3. Use an LLM (e.g., OpenAI, Gemini,  Claude or Groq/HuggingFace) to \\ngenerate an answer using the retrieved context. \\n4. Show a simple reflection or validation step where the agent checks if the \\nanswer is relevant to the question. \\nThe agent workflow should have at least four LangGraph nodes:',\n",
       "  '[5] or pulse rate affected by anxiety, or may look pale or per-\\nspire heavily, but others may appear physically completely\\nnormal. The doctor will then take the patient’s medication,\\ndietary, and occupational history to see if they are taking\\nprescription drugs that might cause anxiety, if they are\\nabusing alcohol or mood-altering drugs, if they are con-\\nsuming large amounts of caffeine, or if their workplace is\\nnoisy or dangerous. In most cases, the most important\\nsource of diagnostic information is the patient’s psycholog-\\nical and social history. The doctor may administer a brief\\npsychological test to help evaluate the intensity of the\\npatient’s anxiety and some of its features. Some tests that\\nare often given include the Hamilton Anxiety Scale and the\\nAnxiety Disorders Interview Schedule (ADIS). Many doc-\\ntors will check a number of chemical factors in the blood,']}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Run a sample query\n",
    "state = AgentState(messages=[{\"role\": \"user\", \"content\": \"What are the main requirements of the interview task?\"}])\n",
    "out = app.invoke(state)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0fd13-7897-46f3-9601-867154db6927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
